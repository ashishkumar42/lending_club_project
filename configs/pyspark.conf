#This file contains configuration settings for different environments in a PySpark application.
[LOCAL]
spark.app.name = lending_app_local
spark.hadoop.fs.file.impl = org.apache.hadoop.fs.LocalFileSystem
spark.sql.parquet.output.committer.class = org.apache.spark.sql.execution.datasources.parquet.DirectParquetOutputCommitter

[DEV]
spark.app.name = lending_app_dev
spark.executor.instances = 2
spark.executor.memory = 4g
spark.executor.cores = 2

[PROD]
spark.app.name = lending_app_prod
spark.executor.instances = 4
spark.executor.memory = 8g
spark.executor.cores = 4